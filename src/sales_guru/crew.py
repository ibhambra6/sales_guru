import os
import time
import logging
import random
from dotenv import load_dotenv
from crewai import Agent, Crew, Process, Task, LLM
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool, CSVSearchTool, FileReadTool, WebsiteSearchTool, ScrapeWebsiteTool
from pydantic import BaseModel

from sales_guru.task_monitor import TaskCompletionMonitor, ensure_task_completion
from sales_guru.tools import TaskValidatorTool
from sales_guru.schemas import (
    LeadQualificationResponse, ProspectResearchResponse, 
    EmailOutreachResponse, SalesCallPrepResponse
)

# Configure logging
logger = logging.getLogger("SalesGuru")

# Load environment variables from .env file
load_dotenv()

# Get API keys from environment variables
serper_api_key = os.getenv('SERPER_API_KEY')
google_api_key = os.getenv('GOOGLE_API_KEY')
openai_api_key = os.getenv('OPENAI_API_KEY')
# If you want to run a snippet of code before or after the crew starts, 
# you can use the @before_kickoff and @after_kickoff decorators
# https://docs.crewai.com/concepts/crews#example-crew-class-with-decorators

# Initialize tools
web_search_tool = SerperDevTool()
csv_search_tool = CSVSearchTool(file_path='knowledge/leads.csv')
csv_read_tool = FileReadTool(file_path='knowledge/leads.csv')
task_validator_tool = TaskValidatorTool()
scrape_web_tool = ScrapeWebsiteTool()

class RateLimitedLLM:
    """Wrapper around LLM to handle rate limits and empty responses with exponential backoff"""
    
    def __init__(self, model, api_key, temperature=0.7, max_retries=3):
        self.model_name = model
        self.base_llm = LLM(
            model=model,
            api_key=api_key,
            temperature=temperature
        )
        self.max_retries = max_retries
        
        # Apply our safe generate method to handle empty responses
        if hasattr(self.base_llm, '_generate'):
            self.base_llm._original_generate = self.base_llm._generate
            self.base_llm._generate = self._safe_generate.__get__(self.base_llm)
        
    def __call__(self, *args, **kwargs):
        """Make the LLM callable directly"""
        return self.call(*args, **kwargs)
        
    def __getattr__(self, name):
        """Delegate attribute access to the base LLM"""
        return getattr(self.base_llm, name)

    def _is_empty_response(self, response):
        """Check if a response is empty or None"""
        return response is None or (isinstance(response, str) and not response.strip())
        
    def call(self, *args, **kwargs):
        """Handle LLM calls with retry logic for common errors"""
        retries = 0
        last_error = None
        
        while retries <= self.max_retries:
            try:
                # Get the raw response
                response = self.base_llm.call(*args, **kwargs)
                
                # Check if response is empty
                if self._is_empty_response(response):
                    logger.warning(f"Empty response from LLM on attempt {retries+1}/{self.max_retries+1}")
                    retries += 1
                    
                    if retries > self.max_retries:
                        break
                        
                    wait_time = self._calculate_wait_time(retries)
                    logger.info(f"Waiting {wait_time:.1f}s before retry due to empty response")
                    time.sleep(wait_time)
                    continue
                
                # We have a valid non-empty response
                return response
                
            except Exception as e:
                last_error = e
                error_msg = str(e).lower()
                retries += 1
                
                wait_time = self._calculate_wait_time(retries)
                
                # Check for common errors that can be retried
                if any(x in error_msg for x in [
                    "rate limit", "429", "too many requests", 
                    "invalid response", "empty",
                    "connection reset", "connection error", "timeout", 
                    "network", "[errno", "socket"
                ]):
                    logger.warning(f"Error: {e}. Waiting {wait_time:.1f}s before retry {retries}/{self.max_retries}")
                    time.sleep(wait_time)
                    
                    if retries > self.max_retries:
                        break
                else:
                    # Other errors should be raised immediately
                    raise
        
        # If we've exhausted retries, return a fallback response
        logger.error(f"Max retries exceeded. Last error: {last_error}")
        return self._get_fallback_response(*args, **kwargs)
    
    def _calculate_wait_time(self, retries):
        """Calculate wait time with exponential backoff and jitter"""
        base_wait_time = min(2 ** (retries + 2), 300)  # exponential backoff with cap at 5 min
        jitter = random.uniform(0.8, 1.2)  # Add Â±20% jitter
        return base_wait_time * jitter
    
    def _get_fallback_response(self, *args, **kwargs):
        """Return a guaranteed non-empty fallback response with task-specific information if possible"""
        fallback_prompt = args[0] if args else kwargs.get('prompt', '')
        is_lead_task = 'lead' in fallback_prompt.lower() if isinstance(fallback_prompt, str) else False
        
        if is_lead_task:
            return """
            I apologize for the technical difficulties. Here's a partial response:
            
            {
                "leads": [
                    {
                        "name": "John Smith",
                        "lead_score": 7,
                        "classification": "Qualified",
                        "reasoning": "Based on available information, this lead shows interest and fits our target profile.",
                        "value_alignment": "Medium",
                        "recommended_approach": "Follow up with a personalized email highlighting specific benefits."
                    }
                ]
            }
            
            Note: This is a fallback response due to technical issues. Please retry with more specific requirements.
            """
        else:
            return "I apologize, but I encountered technical difficulties and couldn't complete this task properly. Please retry or simplify the request. As a fallback, I recommend proceeding with the most promising leads identified so far and scheduling follow-up communications."
    
    def _safe_generate(self, *args, **kwargs):
        """Override the _generate method to ensure we never return empty responses"""
        try:
            response = self._original_generate(*args, **kwargs)
            
            if self._is_empty_response(response):
                logger.warning("Empty response detected in _generate method. Using fallback.")
                return "I apologize, but I encountered a technical issue. Please consider this a partial response based on the available information."
                
            return response
        except Exception as e:
            logger.error(f"Error in _generate method: {e}")
            return "I apologize, but I encountered a technical issue. Please consider this a partial response based on the available information."

# Configure LiteLLM to handle network connectivity issues better
import litellm
litellm.num_retries = 5  # Set higher number of retries for API calls
litellm.request_timeout = 120  # Increase timeout for API calls
litellm.set_verbose = True  # Enable verbose logging for debugging

# Initialize the rate-limited LLMs
google_llm = RateLimitedLLM(
    model="gemini/gemini-2.0-flash",
    api_key=google_api_key,
    temperature=0.7
)

openai_llm = RateLimitedLLM(
    model="gpt-4o",
    api_key=openai_api_key,
    temperature=0.7
)

@CrewBase
class SalesGuru():
	"""SalesGuru crew with task completion guarantees"""

	# Learn more about YAML configuration files here:
	# Agents: https://docs.crewai.com/concepts/agents#yaml-configuration-recommended
	# Tasks: https://docs.crewai.com/concepts/tasks#yaml-configuration-recommended
	agents_config = 'config/agents.yaml'
	tasks_config = 'config/tasks.yaml'
	
	def __init__(self):
		"""Initialize the SalesGuru crew with task completion monitoring."""
		# Initialize task monitoring with simplified settings
		self.task_monitor = TaskCompletionMonitor(
			max_retries=3,
			enable_logging=True,
			model="gpt-4o",
			token_limit_per_min=28000
		)

	# If you would like to add tools to your agents, you can learn more about it here:
	# https://docs.crewai.com/concepts/agents#agent-tools
	@agent
	def lead_qualification(self) -> Agent:
		agent = Agent(
			config=self.agents_config['lead_qualification'],
			tools=[csv_search_tool, csv_read_tool, web_search_tool, task_validator_tool],
			verbose=True,
			llm=google_llm,
			response_format=LeadQualificationResponse
		)
		# Enhance the agent with completion guarantees
		return self.task_monitor.enhance_agent(agent)

	@agent
	def prospect_research(self) -> Agent:
		agent = Agent(
			config=self.agents_config['prospect_research'],
			tools=[web_search_tool, task_validator_tool, scrape_web_tool],
			verbose=True,
			llm=google_llm,
			response_format=ProspectResearchResponse
		)
		# Enhance the agent with completion guarantees
		return self.task_monitor.enhance_agent(agent)

	@agent
	def email_outreach(self) -> Agent:
		agent = Agent(
			config=self.agents_config['email_outreach'],
			tools=[task_validator_tool],
			verbose=True,
            llm=openai_llm,
            response_format=EmailOutreachResponse
		)
		# Enhance the agent with completion guarantees
		return self.task_monitor.enhance_agent(agent)

	@agent
	def sales_call_prep(self) -> Agent:
		agent = Agent(
			config=self.agents_config['sales_call_prep'],
			tools=[task_validator_tool],
			verbose=True,
            llm=openai_llm,
            response_format=SalesCallPrepResponse
		)
		# Enhance the agent with completion guarantees
		return self.task_monitor.enhance_agent(agent)

	# To learn more about structured task outputs, 
	# task dependencies, and task callbacks, check out the documentation:
	# https://docs.crewai.com/concepts/tasks#overview-of-a-task
	@task
	def lead_qualification_task(self) -> Task:
		task = Task(
			config=self.tasks_config['lead_qualification_task'],
			agent=self.lead_qualification()
		)
		# Enhance the task with completion guarantees
		return self.task_monitor.enhance_task(task)
	
	@task
	def prospect_research_task(self) -> Task:
		task = Task(
			config=self.tasks_config['prospect_research_task'],
			agent=self.prospect_research(),
			context=[self.lead_qualification_task()]
		)
		# Enhance the task with completion guarantees
		return self.task_monitor.enhance_task(task)
	
	@task
	def email_outreach_task(self) -> Task:
		task = Task(
			config=self.tasks_config['email_outreach_task'],
			agent=self.email_outreach(),
			context=[self.prospect_research_task(), self.lead_qualification_task()]
		)
		# Enhance the task with completion guarantees
		return self.task_monitor.enhance_task(task)
	
	@task
	def sales_call_prep_task(self) -> Task:
		task = Task(
			config=self.tasks_config['sales_call_prep_task'],
			agent=self.sales_call_prep(),
			context=[self.email_outreach_task(), self.prospect_research_task(), self.lead_qualification_task()]
		)
		# Enhance the task with completion guarantees
		return self.task_monitor.enhance_task(task)
	
	@agent
	def supervisor_agent(self) -> Agent:
		agent = Agent(
			config=self.agents_config['supervisor'],
			verbose=True,  
			llm=google_llm,  # Use the rate limited LLM
            allow_delegation=True
            # No response_format for supervisor since it delegates tasks rather than returning structured data
		)
		return self.task_monitor.enhance_agent(agent)

	@crew
	def crew(self) -> Crew:
		"""Creates the SalesGuru crew with task completion guarantees"""
		# To learn how to add knowledge sources to your crew, check out the documentation:
		# https://docs.crewai.com/concepts/knowledge#what-is-knowledge

		return Crew(
			agents=[self.lead_qualification(), self.prospect_research(), self.email_outreach(), self.sales_call_prep()], # Automatically created by the @agent decorator
			tasks=[self.lead_qualification_task(), self.prospect_research_task(), self.email_outreach_task(), self.sales_call_prep_task()], # Only include task agents, not the supervisor task
			manager_agent=self.supervisor_agent(),
			verbose=True,
			process=Process.hierarchical, # Using hierarchical process for manager supervision
		)
	
	@ensure_task_completion
	def kickoff(self, inputs=None):
		"""Run the crew with task completion guarantees."""
		# The @ensure_task_completion decorator will make sure all tasks are completed
		result = self.crew().kickoff(inputs=inputs)
		# Ensure we never return None, which would cause 'NoneType' object is not callable errors
		if result is None:
			logger.info("CrewAI kickoff returned None, replacing with empty dict")
			return {}
		return result
	
	@ensure_task_completion
	def train(self, n_iterations=1, filename=None, inputs=None):
		"""Train the crew with task completion guarantees."""
		result = self.crew().train(n_iterations=n_iterations, filename=filename, inputs=inputs)
		if result is None:
			logger.info("CrewAI train returned None, replacing with empty dict")
			return {}
		return result
	
	@ensure_task_completion
	def replay(self, task_id=None):
		"""Replay a specific task with task completion guarantees."""
		result = self.crew().replay(task_id=task_id)
		if result is None:
			logger.info("CrewAI replay returned None, replacing with empty dict")
			return {}
		return result
	
	@ensure_task_completion
	def test(self, n_iterations=1, openai_model_name=None, inputs=None):
		"""Test the crew with task completion guarantees."""
		result = self.crew().test(n_iterations=n_iterations, openai_model_name=openai_model_name, inputs=inputs)
		if result is None:
			logger.info("CrewAI test returned None, replacing with empty dict")
			return {}
		return result
